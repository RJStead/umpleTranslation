namespace weka.classifiers.bayes.net.search.local;

class SimulatedAnnealing
{
  isA TechnicalInformationHandler;
  isA LocalScoreSearchAlgorithm;
 depend java.util.Collections;
 depend java.util.Enumeration;
 depend java.util.Random;
 depend java.util.Vector;
 depend weka.classifiers.bayes.BayesNet;
 depend weka.core.Instances;
 depend weka.core.Option;
 depend weka.core.RevisionUtils;
 depend weka.core.TechnicalInformation;
 depend weka.core.TechnicalInformation.Field;
 depend weka.core.TechnicalInformation.Type;
 depend weka.core.TechnicalInformationHandler;
 depend weka.core.Utils;
/** 
 * for serialization 
 */
static final long serialVersionUID=6951955606060513191L;

/** 
 * start temperature 
 */
double m_fTStart=10;

/** 
 * change in temperature at every run 
 */
double m_fDelta=0.999;

/** 
 * number of runs 
 */
int m_nRuns=10000;

/** 
 * use the arc reversal operator 
 */
boolean m_bUseArcReversal=false;

/** 
 * random number seed 
 */
int m_nSeed=1;

/** 
 * random number generator 
 */
Random m_random;

/** 
 * Returns an instance of a TechnicalInformation object, containing detailed information about the technical background of this class, e.g., paper reference or book this class is based on.
 * @return the technical information about this class
 */
@Override public TechnicalInformation getTechnicalInformation(){
  TechnicalInformation result;
  result=new TechnicalInformation(Type.PHDTHESIS);
  result.setValue(Field.AUTHOR,"R.R. Bouckaert");
  result.setValue(Field.YEAR,"1995");
  result.setValue(Field.TITLE,"Bayesian Belief Networks: from Construction to Inference");
  result.setValue(Field.INSTITUTION,"University of Utrecht");
  result.setValue(Field.ADDRESS,"Utrecht, Netherlands");
  return result;
}

/** 
 * @param bayesNet the network
 * @param instances the data to use
 * @throws Exception if something goes wrong
 */
@Override public void search(BayesNet bayesNet,Instances instances) throws Exception {
  m_random=new Random(m_nSeed);
  double[] fBaseScores=new double[instances.numAttributes()];
  double fCurrentScore=0;
  for (int iAttribute=0; iAttribute < instances.numAttributes(); iAttribute++) {
    fBaseScores[iAttribute]=calcNodeScore(iAttribute);
    fCurrentScore+=fBaseScores[iAttribute];
  }
  double fBestScore=fCurrentScore;
  BayesNet bestBayesNet=new BayesNet();
  bestBayesNet.m_Instances=instances;
  bestBayesNet.initStructure();
  copyParentSets(bestBayesNet,bayesNet);
  double fTemp=m_fTStart;
  for (int iRun=0; iRun < m_nRuns; iRun++) {
    boolean bRunSucces=false;
    double fDeltaScore=0.0;
    while (!bRunSucces) {
      int iTailNode=Math.abs(m_random.nextInt()) % instances.numAttributes();
      int iHeadNode=Math.abs(m_random.nextInt()) % instances.numAttributes();
      while (iTailNode == iHeadNode) {
        iHeadNode=Math.abs(m_random.nextInt()) % instances.numAttributes();
      }
      if (isArc(bayesNet,iHeadNode,iTailNode)) {
        bRunSucces=true;
        bayesNet.getParentSet(iHeadNode).deleteParent(iTailNode,instances);
        double fScore=calcNodeScore(iHeadNode);
        fDeltaScore=fScore - fBaseScores[iHeadNode];
        if (fTemp * Math.log((Math.abs(m_random.nextInt()) % 10000) / 10000.0 + 1e-100) < fDeltaScore) {
          fCurrentScore+=fDeltaScore;
          fBaseScores[iHeadNode]=fScore;
        }
 else {
          bayesNet.getParentSet(iHeadNode).addParent(iTailNode,instances);
        }
      }
 else {
        if (addArcMakesSense(bayesNet,instances,iHeadNode,iTailNode)) {
          bRunSucces=true;
          double fScore=calcScoreWithExtraParent(iHeadNode,iTailNode);
          fDeltaScore=fScore - fBaseScores[iHeadNode];
          if (fTemp * Math.log((Math.abs(m_random.nextInt()) % 10000) / 10000.0 + 1e-100) < fDeltaScore) {
            bayesNet.getParentSet(iHeadNode).addParent(iTailNode,instances);
            fBaseScores[iHeadNode]=fScore;
            fCurrentScore+=fDeltaScore;
          }
        }
      }
    }
    if (fCurrentScore > fBestScore) {
      copyParentSets(bestBayesNet,bayesNet);
    }
    fTemp=fTemp * m_fDelta;
  }
  copyParentSets(bayesNet,bestBayesNet);
}

/** 
 * CopyParentSets copies parent sets of source to dest BayesNet
 * @param dest destination network
 * @param source source network
 */
void copyParentSets(BayesNet dest,BayesNet source){
  int nNodes=source.getNrOfNodes();
  for (int iNode=0; iNode < nNodes; iNode++) {
    dest.getParentSet(iNode).copy(source.getParentSet(iNode));
  }
}

/** 
 * @return double
 */
public double getDelta(){
  return m_fDelta;
}

/** 
 * @return double
 */
public double getTStart(){
  return m_fTStart;
}

/** 
 * @return int
 */
public int getRuns(){
  return m_nRuns;
}

/** 
 * Sets the m_fDelta.
 * @param fDelta The m_fDelta to set
 */
public void setDelta(double fDelta){
  m_fDelta=fDelta;
}

/** 
 * Sets the m_fTStart.
 * @param fTStart The m_fTStart to set
 */
public void setTStart(double fTStart){
  m_fTStart=fTStart;
}

/** 
 * Sets the m_nRuns.
 * @param nRuns The m_nRuns to set
 */
public void setRuns(int nRuns){
  m_nRuns=nRuns;
}

/** 
 * @return random number seed
 */
public int getSeed(){
  return m_nSeed;
}

/** 
 * Sets the random number seed
 * @param nSeed The number of the seed to set
 */
public void setSeed(int nSeed){
  m_nSeed=nSeed;
}

/** 
 * Returns an enumeration describing the available options.
 * @return an enumeration of all the available options.
 */
@Override public Enumeration<Option> listOptions(){
  Vector<Option> newVector=new Vector<Option>(4);
  newVector.addElement(new Option("\tStart temperature","A",1,"-A <float>"));
  newVector.addElement(new Option("\tNumber of runs","U",1,"-U <integer>"));
  newVector.addElement(new Option("\tDelta temperature","D",1,"-D <float>"));
  newVector.addElement(new Option("\tRandom number seed","R",1,"-R <seed>"));
  newVector.addAll(Collections.list(super.listOptions()));
  return newVector.elements();
}

/** 
 * Parses a given list of options. <p/> <!-- options-start --> Valid options are: <p/> <pre> -A &lt;float&gt; Start temperature </pre> <pre> -U &lt;integer&gt; Number of runs </pre> <pre> -D &lt;float&gt; Delta temperature </pre> <pre> -R &lt;seed&gt; Random number seed </pre> <pre> -mbc Applies a Markov Blanket correction to the network structure,  after a network structure is learned. This ensures that all  nodes in the network are part of the Markov blanket of the  classifier node. </pre> <pre> -S [BAYES|MDL|ENTROPY|AIC|CROSS_CLASSIC|CROSS_BAYES] Score type (BAYES, BDeu, MDL, ENTROPY and AIC) </pre> <!-- options-end -->
 * @param options the list of options as an array of strings
 * @throws Exception if an option is not supported
 */
@Override public void setOptions(String[] options) throws Exception {
  String sTStart=Utils.getOption('A',options);
  if (sTStart.length() != 0) {
    setTStart(Double.parseDouble(sTStart));
  }
  String sRuns=Utils.getOption('U',options);
  if (sRuns.length() != 0) {
    setRuns(Integer.parseInt(sRuns));
  }
  String sDelta=Utils.getOption('D',options);
  if (sDelta.length() != 0) {
    setDelta(Double.parseDouble(sDelta));
  }
  String sSeed=Utils.getOption('R',options);
  if (sSeed.length() != 0) {
    setSeed(Integer.parseInt(sSeed));
  }
  super.setOptions(options);
}

/** 
 * Gets the current settings of the search algorithm.
 * @return an array of strings suitable for passing to setOptions
 */
@Override public String[] getOptions(){
  Vector<String> options=new Vector<String>();
  options.add("-A");
  options.add("" + getTStart());
  options.add("-U");
  options.add("" + getRuns());
  options.add("-D");
  options.add("" + getDelta());
  options.add("-R");
  options.add("" + getSeed());
  Collections.addAll(options,super.getOptions());
  return options.toArray(new String[0]);
}

/** 
 * This will return a string describing the classifier.
 * @return The string.
 */
@Override public String globalInfo(){
  return "This Bayes Network learning algorithm uses the general purpose search method " + "of simulated annealing to find a well scoring network structure.\n\n" + "For more information see:\n\n"+ getTechnicalInformation().toString();
}

/** 
 * @return a string to describe the TStart option.
 */
public String TStartTipText(){
  return "Sets the start temperature of the simulated annealing search. " + "The start temperature determines the probability that a step in the 'wrong' direction in the " + "search space is accepted. The higher the temperature, the higher the probability of acceptance.";
}

/** 
 * @return a string to describe the Runs option.
 */
public String runsTipText(){
  return "Sets the number of iterations to be performed by the simulated annealing search.";
}

/** 
 * @return a string to describe the Delta option.
 */
public String deltaTipText(){
  return "Sets the factor with which the temperature (and thus the acceptance probability of " + "steps in the wrong direction in the search space) is decreased in each iteration.";
}

/** 
 * @return a string to describe the Seed option.
 */
public String seedTipText(){
  return "Initialization value for random number generator." + " Setting the seed allows replicability of experiments.";
}

/** 
 * Returns the revision string.
 * @return the revision
 */
@Override public String getRevision(){
  return RevisionUtils.extract("$Revision: 10154 $");
}
}
